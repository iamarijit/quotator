{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quotator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCxR4WwyhxKK"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigyaxXzQimg",
        "outputId": "430f3217-9daf-4018-8137-bc8aab5aa7eb"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1dPCpNIUxqhe2GccLF0tmAapnwgA5Olr2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dPCpNIUxqhe2GccLF0tmAapnwgA5Olr2\n",
            "To: /content/quotes_dataset.csv\n",
            "165MB [00:00, 180MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJnm0JLGgbb"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQDApFX9RrjY"
      },
      "source": [
        "import pandas as pd\r\n",
        "import string\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BILE4y8zkjAB"
      },
      "source": [
        "# Initialize Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX6FTxnWY1L3"
      },
      "source": [
        "START_TOKEN = \"<str>\"\r\n",
        "END_TOKEN = \"<end>\"\r\n",
        "PAD_TOKEN = \"<pad>\"\r\n",
        "SPECIAL_TOKEN = \"<spc>\"\r\n",
        "FREQUENCY_THRESOLD = 1\r\n",
        "\r\n",
        "MAX_QUOTE_LEN = 8\r\n",
        "MIN_QUOTE_LEN = 6\r\n",
        "\r\n",
        "BATCH_SIZE = 64\r\n",
        "EMB_SIZE = 256\r\n",
        "NUM_LAYERS = 1\r\n",
        "LSTM_SIZE = 256\r\n",
        "LEARNING_RATE = 0.001\r\n",
        "\r\n",
        "CUDA = torch.cuda.is_available()\r\n",
        "DEVICE = torch.device(\"cuda\") if CUDA else torch.device(\"cpu\")"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kZ-hqMFGpcJ"
      },
      "source": [
        "# Preprocess Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOcehHNadJuj"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8OSp36GpFS",
        "outputId": "f29e0494-a187-4bf8-fb9b-0c610e7f34cf"
      },
      "source": [
        "quote_df = pd.read_csv('quotes_dataset.csv')\r\n",
        "quotes = list(quote_df.iloc[:, 0])"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26,29,31,36,39,40,41) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG1YXVNbdLit"
      },
      "source": [
        "## Clean & tokenize text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdhs2csNXiC2"
      },
      "source": [
        "def clean(text):\r\n",
        "  text = str(text)\r\n",
        "  text = text.lower().strip()\r\n",
        "\r\n",
        "  text = re.sub(r\"won\\'t\", \"will not\", text)\r\n",
        "  text = re.sub(r\"can\\'t\", \"can not\", text)\r\n",
        "\r\n",
        "  # general\r\n",
        "  text = re.sub(r\"n\\'t\", \" not\", text)\r\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\r\n",
        "  text = re.sub(r\"\\'s\", \" is\", text)\r\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\r\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\r\n",
        "  text = re.sub(r\"\\'t\", \" not\", text)\r\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\r\n",
        "  text = re.sub(r\"\\'m\", \" am\", text)\r\n",
        "  \r\n",
        "  for p in string.punctuation:\r\n",
        "    text = text.replace(p, \" \")\r\n",
        "  \r\n",
        "  text = re.sub(r\"\\s{2,}\", \" \", text)\r\n",
        "  return START_TOKEN + \" \" + text.strip() + \" \" + END_TOKEN"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjTKlDk8RtCA"
      },
      "source": [
        "quotes_cleaned = [clean(i).split() for i in quotes if str(i) != 'nan']"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSOfqDLGDUvh"
      },
      "source": [
        "processed_quotes = []\r\n",
        "\r\n",
        "for q in quotes_cleaned:\r\n",
        "  if len(q) >= MIN_QUOTE_LEN and len(q) <= MAX_QUOTE_LEN:\r\n",
        "    processed_quotes.append(q)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Amn7ey26_2j",
        "outputId": "955e2cab-2600-4dc1-ed9d-8af1325d20e7"
      },
      "source": [
        "print(\"Total \" + str(len(processed_quotes)) + \" quotes selected having word count between \" + str(MIN_QUOTE_LEN-2) + \" and \" + str(MAX_QUOTE_LEN-2))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 16393 quotes selected having word count between 4 and 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9XZigO-dN5h"
      },
      "source": [
        "## Create word frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpBaXxmZUUsM"
      },
      "source": [
        "word_frequency_dict = {}\r\n",
        "\r\n",
        "for q in processed_quotes:\r\n",
        "  for word in q:\r\n",
        "    if word not in word_frequency_dict:\r\n",
        "      word_frequency_dict[word] = 1\r\n",
        "    else:\r\n",
        "      word_frequency_dict[word] += 1"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS6XCenegCme"
      },
      "source": [
        "## Create word-integer mappings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nG3qbMYgBGe"
      },
      "source": [
        "word_to_int = {}\r\n",
        "int_to_word = {}\r\n",
        "\r\n",
        "word_to_int[PAD_TOKEN] = 0\r\n",
        "int_to_word[0] = PAD_TOKEN\r\n",
        "word_to_int[SPECIAL_TOKEN] = 1\r\n",
        "int_to_word[1] = SPECIAL_TOKEN\r\n",
        "\r\n",
        "index = 2\r\n",
        "for word, freq in word_frequency_dict.items():\r\n",
        "  if freq > FREQUENCY_THRESOLD:\r\n",
        "    word_to_int[word] = index\r\n",
        "    int_to_word[index] = word\r\n",
        "\r\n",
        "    index += 1"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmaX9RxkFM4b"
      },
      "source": [
        "vocab = pd.DataFrame()\r\n",
        "\r\n",
        "vocab['Words'] = list(word_to_int.keys())\r\n",
        "vocab['ID'] = list(word_to_int.values())\r\n",
        "\r\n",
        "vocab.to_csv('vocab.csv')"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP1I06qO3Syx",
        "outputId": "79e1bc85-edc0-4085-b2a9-42f9f2b5444a"
      },
      "source": [
        "print(\"The size of vocabulary is \" + str(len(word_to_int)))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of vocabulary is 3138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr3D7de2xibu"
      },
      "source": [
        "## Filter & Pad text\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnXRAToP2xCi"
      },
      "source": [
        "def filter_pad(text_tokens):\r\n",
        "  for q in range(len(text_tokens)):\r\n",
        "    if text_tokens[q] not in word_to_int:\r\n",
        "      text_tokens[q] = SPECIAL_TOKEN\r\n",
        "\r\n",
        "  text_tokens = text_tokens + [PAD_TOKEN] * (MAX_QUOTE_LEN - len(text_tokens))\r\n",
        "  \r\n",
        "  return text_tokens"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-acGpxUUhG"
      },
      "source": [
        "processed_quotes = [filter_pad(q) for q in processed_quotes]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrzPhFSuZAWm"
      },
      "source": [
        "## Map tokens to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylZIVhPEUUV_"
      },
      "source": [
        "def map_word_to_int(text_tokens):\r\n",
        "  return [word_to_int[i] for i in text_tokens]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UBtfiWaSXZ"
      },
      "source": [
        "def map_int_to_word(text_tokens):\r\n",
        "  return [int_to_word[i] for i in text_tokens]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyBKpxC4aSUy"
      },
      "source": [
        "processed_quotes = [map_word_to_int(q) for q in processed_quotes]"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC504B6GqxTx"
      },
      "source": [
        "# Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjFUPgbHUUSe"
      },
      "source": [
        "class QuoteDataset(Dataset):\r\n",
        "  def __init__(self, quotes=processed_quotes):\r\n",
        "    self.quotes = np.array(quotes)\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.quotes)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    quote = self.quotes[index]\r\n",
        "    data = {\r\n",
        "        'x': torch.from_numpy(quote[:-1]), \r\n",
        "        'y': torch.from_numpy(quote[1:])\r\n",
        "        }\r\n",
        "    return data"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIF3MizhIvme"
      },
      "source": [
        "dataset = QuoteDataset(quotes=processed_quotes)\r\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HmaSXtERs5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf532654-0fb8-4af4-ef00-809d0f4e2ea1"
      },
      "source": [
        "for batch in dataloader:\r\n",
        "  print(batch['x'].shape, batch['y'].shape)\r\n",
        "  break"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 7]) torch.Size([64, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQyepwVJy0ly"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTjlw6rTRs10"
      },
      "source": [
        "class Model(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Model, self).__init__()\r\n",
        "\r\n",
        "    self.vocab_size = len(word_to_int)\r\n",
        "    self.lstm_size = LSTM_SIZE\r\n",
        "    self.embedding_dim = EMB_SIZE\r\n",
        "    self.num_layers = NUM_LAYERS\r\n",
        "\r\n",
        "    self.emb = nn.Embedding(\r\n",
        "        num_embeddings=self.vocab_size, \r\n",
        "        embedding_dim=self.embedding_dim\r\n",
        "        )\r\n",
        "    self.lstm = nn.LSTM(\r\n",
        "        input_size=self.embedding_dim,\r\n",
        "        hidden_size=self.lstm_size,\r\n",
        "        num_layers=self.num_layers\r\n",
        "        )\r\n",
        "    self.fc = nn.Linear(self.lstm_size, self.vocab_size)\r\n",
        "\r\n",
        "  def forward(self, x, prev_state):\r\n",
        "    emb = self.emb(x)\r\n",
        "    output, state = self.lstm(emb, prev_state)\r\n",
        "    y = self.fc(output)\r\n",
        "    return y, state\r\n",
        "\r\n",
        "  def init_state(self, seq_length):\r\n",
        "    return (\r\n",
        "        torch.zeros(self.num_layers, seq_length, self.lstm_size).to(DEVICE),\r\n",
        "        torch.zeros(self.num_layers, seq_length, self.lstm_size).to(DEVICE)\r\n",
        "    )"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW2bO1sCAINg"
      },
      "source": [
        "# Training & Quote Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLS39fm9Rsv2"
      },
      "source": [
        "def generate(model, max_words=MAX_QUOTE_LEN-2):\r\n",
        "  model.eval()\r\n",
        "  h, c = model.init_state(seq_length=1)\r\n",
        "\r\n",
        "  x = torch.from_numpy(np.array([word_to_int[START_TOKEN]])).to(DEVICE)\r\n",
        "  x = x.unsqueeze(0)\r\n",
        "\r\n",
        "  words = []\r\n",
        "  for w in range(max_words):\r\n",
        "    y, (h, c) = model(x, (h, c))        \r\n",
        "    y = y[0][-1]\r\n",
        "\r\n",
        "    # topk, indices = torch.topk(y, 10)\r\n",
        "    # y[[i for i in range(len(y)) if i not in indices]] = 0\r\n",
        "    \r\n",
        "    p = nn.functional.softmax(y, dim=0).cpu().detach().numpy()\r\n",
        "    word_index = np.random.choice(len(y), p=p)\r\n",
        "\r\n",
        "    while word_index == word_to_int[SPECIAL_TOKEN]:\r\n",
        "      word_index = np.random.choice(len(y), p=p)        \r\n",
        "\r\n",
        "    if int_to_word[word_index] == END_TOKEN or int_to_word[word_index] == PAD_TOKEN:\r\n",
        "      break\r\n",
        "\r\n",
        "    x = torch.from_numpy(np.array([word_index])).to(DEVICE)\r\n",
        "    x = x.unsqueeze(0)\r\n",
        "\r\n",
        "    words.append(int_to_word[word_index])\r\n",
        "\r\n",
        "  return words"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mxQ98vKRsy3"
      },
      "source": [
        "def train(model, dataloader, epochs):  \r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
        "\r\n",
        "  for e in range(epochs):\r\n",
        "    model.train()\r\n",
        "    loss = 0\r\n",
        "    for index, batch in enumerate(dataloader):\r\n",
        "      x = batch['x'].to(DEVICE)\r\n",
        "      y = batch['y'].to(DEVICE)\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "\r\n",
        "      h, c = model.init_state(seq_length=MAX_QUOTE_LEN-1)\r\n",
        "      y_pred, (h, c) = model(x, (h, c))\r\n",
        "\r\n",
        "      batch_loss = criterion(y_pred.transpose(1, 2), y)\r\n",
        "      batch_loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "      loss += batch_loss.item() * x.size(0)\r\n",
        "      # print({ 'Epoch': e, 'Batch': index, 'Loss': batch_loss.item() })\r\n",
        "\r\n",
        "    avg_loss = loss / len(dataloader.sampler)\r\n",
        "    print('Average loss after ' + str(e+1) + ' epoch = ' + str(avg_loss))\r\n",
        "\r\n",
        "    quote = \" \".join(generate(model))\r\n",
        "    print('Sample quote --> ' + quote)  \r\n",
        "\r\n",
        "    print('')\r\n",
        "  \r\n",
        "  torch.save(model.state_dict(), \"model.pt\")"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug_V5L5sRsta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb08c642-dd7a-47bb-c4ee-ba64c0c74076"
      },
      "source": [
        "model = Model().to(DEVICE)\r\n",
        "train(model, dataloader, epochs=50)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss after 1 epoch = 4.685294387339527\n",
            "Sample quote --> love all of business moment is\n",
            "\n",
            "Average loss after 2 epoch = 4.126872152739096\n",
            "Sample quote --> words write your situations made me\n",
            "\n",
            "Average loss after 3 epoch = 3.8973622079489836\n",
            "Sample quote --> music god is sun free without\n",
            "\n",
            "Average loss after 4 epoch = 3.73212630170046\n",
            "Sample quote --> sacred life is a dream sees\n",
            "\n",
            "Average loss after 5 epoch = 3.6050949697343833\n",
            "Sample quote --> every stone towards this\n",
            "\n",
            "Average loss after 6 epoch = 3.4997692533564133\n",
            "Sample quote --> love your sacred people a pretty\n",
            "\n",
            "Average loss after 7 epoch = 3.419645624178801\n",
            "Sample quote --> fear is my life to create\n",
            "\n",
            "Average loss after 8 epoch = 3.3464082544851874\n",
            "Sample quote --> custom is power of understanding leads\n",
            "\n",
            "Average loss after 9 epoch = 3.289383109039249\n",
            "Sample quote --> follow the best revenge is god\n",
            "\n",
            "Average loss after 10 epoch = 3.240859399333152\n",
            "Sample quote --> dwell in hell sunlight is your\n",
            "\n",
            "Average loss after 11 epoch = 3.202788110271815\n",
            "Sample quote --> the wise people too much war\n",
            "\n",
            "Average loss after 12 epoch = 3.165476581870415\n",
            "Sample quote --> speak when it hurts too much\n",
            "\n",
            "Average loss after 13 epoch = 3.1332914191939314\n",
            "Sample quote --> greed without conscience is the only\n",
            "\n",
            "Average loss after 14 epoch = 3.112723374725995\n",
            "Sample quote --> women there salvation is a real\n",
            "\n",
            "Average loss after 15 epoch = 3.090450261791506\n",
            "Sample quote --> who risks gives me and determination\n",
            "\n",
            "Average loss after 16 epoch = 3.0691992751647255\n",
            "Sample quote --> i have got the cat is\n",
            "\n",
            "Average loss after 17 epoch = 3.05418473317422\n",
            "Sample quote --> you don’t live forever is self\n",
            "\n",
            "Average loss after 18 epoch = 3.041571565960933\n",
            "Sample quote --> nothing but trouble\n",
            "\n",
            "Average loss after 19 epoch = 3.0287129022506\n",
            "Sample quote --> example is all to know thy\n",
            "\n",
            "Average loss after 20 epoch = 3.0172857079651068\n",
            "Sample quote --> i am i can’t argue with\n",
            "\n",
            "Average loss after 21 epoch = 3.0073521309292195\n",
            "Sample quote --> despair\n",
            "\n",
            "Average loss after 22 epoch = 2.9974413896897043\n",
            "Sample quote --> men but out of self confidence\n",
            "\n",
            "Average loss after 23 epoch = 2.9871933588076707\n",
            "Sample quote --> trial fail fast fail to the\n",
            "\n",
            "Average loss after 24 epoch = 2.979488913560447\n",
            "Sample quote --> personality is frozen light\n",
            "\n",
            "Average loss after 25 epoch = 2.9753215888897233\n",
            "Sample quote --> forgiveness there is not want to\n",
            "\n",
            "Average loss after 26 epoch = 2.9721694468346564\n",
            "Sample quote --> this shall be grateful for your\n",
            "\n",
            "Average loss after 27 epoch = 2.960242857761717\n",
            "Sample quote --> life a naked\n",
            "\n",
            "Average loss after 28 epoch = 2.956140146198481\n",
            "Sample quote --> audacity always has a world to\n",
            "\n",
            "Average loss after 29 epoch = 2.9514955738381543\n",
            "Sample quote --> expect rarely give love is like\n",
            "\n",
            "Average loss after 30 epoch = 2.9529284886529052\n",
            "Sample quote --> i love has time for creativity\n",
            "\n",
            "Average loss after 31 epoch = 2.943098589855211\n",
            "Sample quote --> the wisdom is your hopes new\n",
            "\n",
            "Average loss after 32 epoch = 2.9424343650746665\n",
            "Sample quote --> listen we live life is a\n",
            "\n",
            "Average loss after 33 epoch = 2.9369218282409286\n",
            "Sample quote --> politics is the poetry in the\n",
            "\n",
            "Average loss after 34 epoch = 2.9353167354635166\n",
            "Sample quote --> war never give positive thoughts have\n",
            "\n",
            "Average loss after 35 epoch = 2.9295884303101856\n",
            "Sample quote --> he wounds into strength of your\n",
            "\n",
            "Average loss after 36 epoch = 2.9291618462704916\n",
            "Sample quote --> the family is the sunrise we\n",
            "\n",
            "Average loss after 37 epoch = 2.9206084593069717\n",
            "Sample quote --> the cancer is real when you\n",
            "\n",
            "Average loss after 38 epoch = 2.923435486527248\n",
            "Sample quote --> romance without means are ordinary can\n",
            "\n",
            "Average loss after 39 epoch = 2.9180285105265744\n",
            "Sample quote --> strange or be written as wisdom\n",
            "\n",
            "Average loss after 40 epoch = 2.9153822118321324\n",
            "Sample quote --> we’re all of stars\n",
            "\n",
            "Average loss after 41 epoch = 2.9149291011403307\n",
            "Sample quote --> america is living is a belief\n",
            "\n",
            "Average loss after 42 epoch = 2.915970282565389\n",
            "Sample quote --> write in the stars are born\n",
            "\n",
            "Average loss after 43 epoch = 2.911676275005118\n",
            "Sample quote --> dreams\n",
            "\n",
            "Average loss after 44 epoch = 2.9105261730128236\n",
            "Sample quote --> never angry people never come and\n",
            "\n",
            "Average loss after 45 epoch = 2.9039975431136607\n",
            "Sample quote --> freedom in a holy poetry for\n",
            "\n",
            "Average loss after 46 epoch = 2.9038853010627776\n",
            "Sample quote --> teamwork great men do not only\n",
            "\n",
            "Average loss after 47 epoch = 2.8992128894901086\n",
            "Sample quote --> love everybody should be happy is\n",
            "\n",
            "Average loss after 48 epoch = 2.900645209531005\n",
            "Sample quote --> but perception not forbidden to action\n",
            "\n",
            "Average loss after 49 epoch = 2.9015696744081674\n",
            "Sample quote --> others\n",
            "\n",
            "Average loss after 50 epoch = 2.894900272918331\n",
            "Sample quote --> gratitude is a gentle soul is\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMIn5tM7RsnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839777f4-730c-4ff4-f8d3-436b66e0876e"
      },
      "source": [
        "model = Model().to(DEVICE)\r\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\r\n",
        "\r\n",
        "for _ in range(10):\r\n",
        "  generated_quote = \" \".join(generate(model)).capitalize()\r\n",
        "  print(generated_quote)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Greater accomplishment\n",
            "The soul is contentment is no\n",
            "Reach out of spirit of destiny\n",
            "Praying is the soul of the\n",
            "Get mad here is a seductive\n",
            "Increased\n",
            "Praying is contagious remember about achieving\n",
            "Stay present stay determined soul has\n",
            "A poet is god direct your\n",
            "Change plus time to dream\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}